{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593395ce",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e8ef54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe993b3",
   "metadata": {},
   "source": [
    "### Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd08cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(dataframes_list: list[pd.DataFrame]) -> pd.DataFrame:\n",
    "    \n",
    "    \n",
    "    # Required columns\n",
    "    required_columns = ['nodeUserID', 'nodeTime', 'videoID', 'platform']\n",
    "    \n",
    "    # Process each dataframe to keep only required columns\n",
    "    processed_dfs = []\n",
    "    for i, df in enumerate(dataframes_list):\n",
    "        # Check if all required columns exist\n",
    "        missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"DataFrame at index {i} is missing required columns: {missing_cols}\")\n",
    "        \n",
    "        # Select only the required columns\n",
    "        processed_df = df[required_columns].copy()\n",
    "        processed_dfs.append(processed_df)\n",
    "    \n",
    "    # Concatenate all processed dataframes\n",
    "    combined_df = pd.concat(processed_dfs, ignore_index=True)  \n",
    "\n",
    "    # Setting datatypes to the columns\n",
    "    combined_df['nodeUserID'] = combined_df['nodeUserID'].astype(str)\n",
    "    combined_df['videoID'] = combined_df['videoID'].astype(str)\n",
    "    combined_df['platform'] = combined_df['platform'].astype(str)\n",
    "    combined_df['nodeTime'] = pd.to_datetime(combined_df['nodeTime'])\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be305f6",
   "metadata": {},
   "source": [
    "### Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2494b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(df: pd.DataFrame) -> nx.Graph:\n",
    "    \n",
    "    # Initialize a new graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes for each unique user with platform attribute\n",
    "    users = df[['nodeUserID', 'platform']].drop_duplicates()\n",
    "    for _, row in users.iterrows():\n",
    "        user_id = f\"user_{row['nodeUserID']}\"\n",
    "        G.add_node(user_id, bipartite=0, platform=row['platform'], node_type='user')\n",
    "    \n",
    "    # Add nodes for each unique video\n",
    "    videos = df['videoID'].unique()\n",
    "    for video_id in videos:\n",
    "        video_node = f\"video_{video_id}\"\n",
    "        G.add_node(video_node, bipartite=1, platform='youtube', node_type='video')\n",
    "    \n",
    "    # Add edges between users and videos\n",
    "    for _, row in df.iterrows():\n",
    "        user_node = f\"user_{row['nodeUserID']}\"\n",
    "        video_node = f\"video_{row['videoID']}\"\n",
    "        G.add_edge(user_node, video_node)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327b0ef0",
   "metadata": {},
   "source": [
    "### Get user interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee8b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_interactions(df: pd.DataFrame, start_seconds_threshold: int = 0, end_seconds_threshold: int = 52) -> pd.DataFrame:\n",
    "\n",
    "    # Ensure 'nodeUserID' is string type\n",
    "    df['nodeUserID'] = df['nodeUserID'].astype(str)\n",
    "\n",
    "    # Ensure 'nodeTime' is datetime type\n",
    "    df['nodeTime'] = pd.to_datetime(df['nodeTime'], errors='coerce')\n",
    "    \n",
    "    # Self-Merge on 'videoID'\n",
    "    # We only select relevant columns to save memory during the merge\n",
    "    subset = df[['nodeUserID', 'nodeTime', 'videoID']]\n",
    "    merged = pd.merge(subset, subset, on='videoID', suffixes=('1', '2'))\n",
    "\n",
    "    # Remove self-loops and duplicate pairs (A-B is same as B-A)\n",
    "    # We enforce UserID1 < UserID2 to ensure unique pairs\n",
    "    merged = merged[merged['nodeUserID1'] < merged['nodeUserID2']]\n",
    "\n",
    "    # Calculate absolute difference between timestamps\n",
    "    time_diff = (merged['nodeTime1'] - merged['nodeTime2']).abs()\n",
    "    \n",
    "    # Converting difference to seconds\n",
    "    seconds_diff = time_diff.dt.total_seconds()\n",
    "    \n",
    "    # Filter based on difference\n",
    "    valid_interactions = merged[seconds_diff.between(start_seconds_threshold, end_seconds_threshold, inclusive='left')]\n",
    "\n",
    "    # Aggregation: Count distinct videoIDs per user pair\n",
    "    result = (\n",
    "        valid_interactions\n",
    "        .groupby(['nodeUserID1', 'nodeUserID2'])['videoID']\n",
    "        .nunique() # Count distinct videos\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Rename column to match requirements\n",
    "    result.rename(columns={'videoID': 'sharedVideos'}, inplace=True)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21364a7b",
   "metadata": {},
   "source": [
    "### Add user interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db150e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user_interaction_edges(G: nx.Graph, df_interactions: pd.DataFrame) -> nx.Graph:\n",
    "    # Create a list of edges in the format: (u, v, attributes_dictionary)\n",
    "    # We use itertuples() because it is much faster than iterrows()\n",
    "    edges_to_add = [\n",
    "        (\n",
    "            \"user_\" + str(row.nodeUserID1), \n",
    "            \"user_\" + str(row.nodeUserID2), \n",
    "            {'sharedVideos': row.sharedVideos}\n",
    "        )\n",
    "        for row in df_interactions.itertuples(index=False)\n",
    "    ]\n",
    "\n",
    "    # Add these edges to the graph in one batch\n",
    "    # If the edge already exists, this will update/overwrite the attribute\n",
    "    G.add_edges_from(edges_to_add)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bf16e0",
   "metadata": {},
   "source": [
    "### Get network metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "df525f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_metrics(G):\n",
    "    # Calculate the metrics\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    num_edges = G.number_of_edges()\n",
    "    density = nx.density(G)\n",
    "    avg_clustering = nx.average_clustering(G)\n",
    "    \n",
    "    # Communities\n",
    "    communities = nx.community.louvain_communities(G)\n",
    "    num_communities = len(communities)\n",
    "    modularity_score = nx.community.modularity(G, communities)\n",
    "\n",
    "    # Handle Components\n",
    "    num_components = nx.number_connected_components(G)\n",
    "    largest_cc = len(max(nx.connected_components(G), key=len))\n",
    "    \n",
    "    # Create the Data Dictionary\n",
    "    stats = {\n",
    "        'nodes': num_nodes,\n",
    "        'edges': num_edges,\n",
    "        'density': round(density, 5),\n",
    "        'avg clustering': round(avg_clustering, 4),\n",
    "        'connected components': num_components,\n",
    "        'largest component size': largest_cc,\n",
    "        'isolates': nx.number_of_isolates(G), # Nodes with 0 connections\n",
    "        'communities': num_communities,\n",
    "        'modularity': modularity_score\n",
    "    }\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_stats = pd.DataFrame(stats, index=[0])\n",
    "    \n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4df9eb4",
   "metadata": {},
   "source": [
    "### Get shared video counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e404df08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shared_video_counts(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Select only necessary \n",
    "    subset = df[['nodeUserID', 'videoID', 'platform']].drop_duplicates()\n",
    "\n",
    "    # Connect every user to every other user who posted the same video\n",
    "    merged = pd.merge(subset, subset, on='videoID', suffixes=('1', '2'))\n",
    "\n",
    "    # Filter Self-Loops and Duplicates\n",
    "    merged = merged[merged['nodeUserID1'] < merged['nodeUserID2']]\n",
    "\n",
    "    # Count how many videoIDs exist for each pair\n",
    "    result = (\n",
    "        merged\n",
    "        .groupby(['nodeUserID1', 'platform1', 'nodeUserID2', 'platform2'])\n",
    "        .size()\n",
    "        .reset_index(name='sharedVideos')\n",
    "    )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36062ca",
   "metadata": {},
   "source": [
    "### Get users network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "207cbfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users_network(df: pd.DataFrame, min_shared_videos: int = 1) -> nx.Graph:\n",
    "    \n",
    "    \n",
    "    # Filter by Threshold\n",
    "    filtered_df = df[df['sharedVideos'] >= min_shared_videos].copy()\n",
    "\n",
    "    # Add prefix to user IDs\n",
    "    filtered_df['nodeUserID1'] = \"user_\" + filtered_df['nodeUserID1'].astype(str)\n",
    "    filtered_df['nodeUserID2'] = \"user_\" + filtered_df['nodeUserID2'].astype(str)\n",
    "    \n",
    "    # Create the Graph and Edges\n",
    "    G = nx.from_pandas_edgelist(\n",
    "        filtered_df,\n",
    "        source='nodeUserID1',\n",
    "        target='nodeUserID2',\n",
    "        edge_attr=['sharedVideos'] \n",
    "    )\n",
    "    \n",
    "    # Explicitly set the 'weight' attribute\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        data['weight'] = data['sharedVideos']\n",
    "\n",
    "    # Assign Node Attributes (Platform)\n",
    "    # Get pairs from column 1\n",
    "    sources = filtered_df[['nodeUserID1', 'platform1']].rename(\n",
    "        columns={'nodeUserID1': 'node', 'platform1': 'platform'}\n",
    "    )\n",
    "    # Get pairs from column 2\n",
    "    targets = filtered_df[['nodeUserID2', 'platform2']].rename(\n",
    "        columns={'nodeUserID2': 'node', 'platform2': 'platform'}\n",
    "    )\n",
    "    \n",
    "    # Combine them and drop duplicates\n",
    "    all_nodes_attr = pd.concat([sources, targets]).drop_duplicates(subset=['node'])\n",
    "    platform_dict = all_nodes_attr.set_index('node')['platform'].to_dict()\n",
    "    \n",
    "    # Apply attributes to the graph\n",
    "    nx.set_node_attributes(G, platform_dict, name='platform')\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415e27e5",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfffb7e",
   "metadata": {},
   "source": [
    "### Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6db6e6",
   "metadata": {},
   "source": [
    "First we need to load the data and explore the structure of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45c95fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodeUserID</th>\n",
       "      <th>nodeTime</th>\n",
       "      <th>videoID</th>\n",
       "      <th>platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>548542</td>\n",
       "      <td>2018-04-01 10:22:08</td>\n",
       "      <td>VLMOHhKkrX8</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5465518</td>\n",
       "      <td>2018-04-05 00:04:00</td>\n",
       "      <td>OBkn78q_t_Q</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6119363</td>\n",
       "      <td>2018-04-05 07:12:02</td>\n",
       "      <td>3wj4ncIEDxw</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8621215</td>\n",
       "      <td>2018-04-05 18:22:26</td>\n",
       "      <td>3wj4ncIEDxw</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12041680</td>\n",
       "      <td>2018-04-08 15:08:50</td>\n",
       "      <td>mvD7qhDwljs</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nodeUserID            nodeTime      videoID  platform\n",
       "0     548542 2018-04-01 10:22:08  VLMOHhKkrX8  facebook\n",
       "1    5465518 2018-04-05 00:04:00  OBkn78q_t_Q  facebook\n",
       "2    6119363 2018-04-05 07:12:02  3wj4ncIEDxw  facebook\n",
       "3    8621215 2018-04-05 18:22:26  3wj4ncIEDxw  facebook\n",
       "4   12041680 2018-04-08 15:08:50  mvD7qhDwljs  facebook"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data from different platforms\n",
    "dfFacebook = pd.read_csv('data/facebook_cross_platform.csv')\n",
    "dfReddit = pd.read_csv('data/reddit_cross_platform.csv')\n",
    "dfTwitter = pd.read_csv(\"data/twitter_cross_platform.csv\")\n",
    "dfYoutube = pd.read_csv(\"data/youtube_cross_platform.csv\")\n",
    "\n",
    "# Combining Data\n",
    "dfCombined = combine_data(dataframes_list = [dfFacebook, dfReddit, dfTwitter])\n",
    "dfCombined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d451091",
   "metadata": {},
   "source": [
    "We are gonna validate that we do not have duplicates of user across platforms that could forces us to transform the IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ac23da67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No users found across multiple platforms.\n"
     ]
    }
   ],
   "source": [
    "# Calculate how many unique platforms each user has\n",
    "platform_counts = dfCombined.groupby('nodeUserID')['platform'].transform('nunique')\n",
    "\n",
    "# Filter the dataframe to keep only users with > 1 platform\n",
    "violators = dfCombined[platform_counts > 1]\n",
    "\n",
    "if not violators.empty:\n",
    "    print(\"Found users across multiple platforms:\")\n",
    "    print(violators.sort_values('nodeUserID'))\n",
    "else:\n",
    "    print(\"No users found across multiple platforms.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ceadec",
   "metadata": {},
   "source": [
    "We validated that user IDs are unique for each platform. Now let's get some statistics about the combined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e495fff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodeUserID</th>\n",
       "      <th>nodeTime</th>\n",
       "      <th>videoID</th>\n",
       "      <th>platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16565</td>\n",
       "      <td>16565</td>\n",
       "      <td>16565</td>\n",
       "      <td>16565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>a0fYqjn3qCvgH6MYNqZRew</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CCmN6X_7kn0</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2342</td>\n",
       "      <td>14942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-13 06:22:50.677452544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-01 02:13:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-23 13:36:24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-22 20:57:37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-12-01 23:45:11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-30 22:14:58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>object</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing %</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       nodeUserID                       nodeTime      videoID  \\\n",
       "count                       16565                          16565        16565   \n",
       "unique                       5897                            NaN          667   \n",
       "top        a0fYqjn3qCvgH6MYNqZRew                            NaN  CCmN6X_7kn0   \n",
       "freq                         2470                            NaN         2342   \n",
       "mean                          NaN  2018-08-13 06:22:50.677452544          NaN   \n",
       "min                           NaN            2018-04-01 02:13:00          NaN   \n",
       "25%                           NaN            2018-04-23 13:36:24          NaN   \n",
       "50%                           NaN            2018-07-22 20:57:37          NaN   \n",
       "75%                           NaN            2018-12-01 23:45:11          NaN   \n",
       "max                           NaN            2019-04-30 22:14:58          NaN   \n",
       "type                       object                 datetime64[ns]       object   \n",
       "missing                         0                              0            0   \n",
       "missing %                     0.0                            0.0          0.0   \n",
       "\n",
       "          platform  \n",
       "count        16565  \n",
       "unique           3  \n",
       "top        twitter  \n",
       "freq         14942  \n",
       "mean           NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  \n",
       "type        object  \n",
       "missing          0  \n",
       "missing %      0.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting some information of the datasets\n",
    "dfDescribe =dfCombined.describe(include='all')\n",
    "dfDescribe = pd.concat([dfDescribe,\n",
    "    pd.DataFrame({\n",
    "        'type': dfCombined.dtypes,\n",
    "        'missing': dfCombined.isnull().sum(),\n",
    "        'missing %': (dfCombined.isnull().mean() * 100).round(2)\n",
    "    }).T\n",
    "])\n",
    "dfDescribe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6bd7d8",
   "metadata": {},
   "source": [
    "From previous tables we validated that datasets were well combined. Also, we don't have any null values which is good for our analysis. Finally, it seems that we got more instances from the twitter dataset.\n",
    "\n",
    "Now we are gonna do the same process with the video dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63e8887f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoID</th>\n",
       "      <th>video_channel</th>\n",
       "      <th>nodeTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zd6bAEMu5Yk</td>\n",
       "      <td>twotwo30Productions</td>\n",
       "      <td>2006-09-22 21:10:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VU3RHNLzh-I</td>\n",
       "      <td>معاٌ لدعم الدفاع المدني السوري</td>\n",
       "      <td>2014-06-19 10:29:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tdFHNE8WxOA</td>\n",
       "      <td>ZFront Kharkov UA</td>\n",
       "      <td>2014-07-08 14:28:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12irnW4FNFY</td>\n",
       "      <td>ODN</td>\n",
       "      <td>2014-07-12 10:25:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6h0VDhENotI</td>\n",
       "      <td>The Syria Campaign</td>\n",
       "      <td>2014-08-27 12:33:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoID                   video_channel             nodeTime\n",
       "0  Zd6bAEMu5Yk             twotwo30Productions  2006-09-22 21:10:44\n",
       "1  VU3RHNLzh-I  معاٌ لدعم الدفاع المدني السوري  2014-06-19 10:29:28\n",
       "2  tdFHNE8WxOA               ZFront Kharkov UA  2014-07-08 14:28:21\n",
       "3  12irnW4FNFY                             ODN  2014-07-12 10:25:05\n",
       "4  6h0VDhENotI              The Syria Campaign  2014-08-27 12:33:36"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYoutube = pd.read_csv(\"data/youtube_cross_platform.csv\")\n",
    "dfYoutube.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fcef684b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoID</th>\n",
       "      <th>video_channel</th>\n",
       "      <th>nodeTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>667</td>\n",
       "      <td>667</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>667</td>\n",
       "      <td>283</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Zd6bAEMu5Yk</td>\n",
       "      <td>vanessa beeley</td>\n",
       "      <td>2006-09-22 21:10:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing %</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               videoID   video_channel             nodeTime\n",
       "count              667             667                  667\n",
       "unique             667             283                  667\n",
       "top        Zd6bAEMu5Yk  vanessa beeley  2006-09-22 21:10:44\n",
       "freq                 1              60                    1\n",
       "type            object          object               object\n",
       "missing              0               0                    0\n",
       "missing %          0.0             0.0                  0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting some information of the datasets\n",
    "dfDescribeVideos =dfYoutube.describe(include='all')\n",
    "dfDescribeVideos = pd.concat([dfDescribeVideos,\n",
    "    pd.DataFrame({\n",
    "        'type': dfYoutube.dtypes,\n",
    "        'missing': dfYoutube.isnull().sum(),\n",
    "        'missing %': (dfYoutube.isnull().mean() * 100).round(2)\n",
    "    }).T\n",
    "])\n",
    "dfDescribeVideos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc3f701",
   "metadata": {},
   "source": [
    "We validated that our videos dataset looks very well. It does not have any null values and any duplicates. We can use these datasets without any transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e89ed0e",
   "metadata": {},
   "source": [
    "### Network Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeb117b",
   "metadata": {},
   "source": [
    "Now let's build the network using the different datasets and get some basic metrics that could help us understand the structure of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c671485e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodes</th>\n",
       "      <th>edges</th>\n",
       "      <th>density</th>\n",
       "      <th>avg clustering</th>\n",
       "      <th>connected components</th>\n",
       "      <th>largest component size</th>\n",
       "      <th>isolates</th>\n",
       "      <th>communities</th>\n",
       "      <th>modularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6564</td>\n",
       "      <td>10262</td>\n",
       "      <td>0.00048</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>100</td>\n",
       "      <td>6235</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0.708567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nodes  edges  density  avg clustering  connected components  \\\n",
       "0   6564  10262  0.00048          0.0783                   100   \n",
       "\n",
       "   largest component size  isolates  communities  modularity  \n",
       "0                    6235         0          136    0.708567  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the connections between users who posted same video\n",
    "dfUserConnections = get_user_interactions(dfCombined, start_seconds_threshold = 0, end_seconds_threshold = 52)\n",
    "\n",
    "# Building the network with connections between users and videos\n",
    "G_original = build_network(dfCombined)\n",
    "\n",
    "# Adding connections between users\n",
    "G_original = add_user_interaction_edges(G_original, dfUserConnections)\n",
    "\n",
    "# Showing metrics from our network\n",
    "dfMetrics = get_network_metrics(G_original)\n",
    "dfMetrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250a08f1",
   "metadata": {},
   "source": [
    "From the previous metrics we can see that we have a very sparse network, this is expected as the network has many nodes. Also, we can see that the network is not connected, there are 100 components. The largest component has 6235 nodes, we can use this component for our analysis. \n",
    "\n",
    "Also it's interesting to see that we have a high value of clustering coefficient. Also the modularity is relative high, this could give us a hint of the community structure of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ffa4d7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 6235\n",
      "Number of edges: 10015\n",
      "Density: 0.000515320825161652\n",
      "Average degree: 3.2125100240577384\n"
     ]
    }
   ],
   "source": [
    "# Getting just the largest component\n",
    "G_transformed = G_original.subgraph(max(nx.connected_components(G_original), key=len))\n",
    "\n",
    "# Writing the network to plot it in Gephi\n",
    "nx.write_gexf(G_transformed, \"transformed_network.gexf\")\n",
    "\n",
    "# Showing some metrics\n",
    "print(\"Number of nodes:\", G_transformed.number_of_nodes())\n",
    "print(\"Number of edges:\", G_transformed.number_of_edges())\n",
    "print(\"Density:\", nx.density(G_transformed))\n",
    "print(\"Average degree:\", np.mean(list(dict(G_transformed.degree()).values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416f5321",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h3> Connected Network of Users and Videos </h3>\n",
    "<img src=\"images/original_network.png\" alt=\"Connected Network of Users and Videos with Gephi\" width=\"600\" height=\"600\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63029f0",
   "metadata": {},
   "source": [
    "From the previous network we can see that there are hubs that concentrate many nodes, presumably because they are viral videos promoted by users with a coordinated strategy. From these hubs we see that there are two types of users connected:\n",
    "- Users that are only connected to one video node. We think that they are users that engaged organically with the video.\n",
    "- Users that are connected to many video nodes. They are located in the center of the network. We think that they could have a coordinated strategy in order to promote some of the videos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fc80d5",
   "metadata": {},
   "source": [
    "### Getting users network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87353f7b",
   "metadata": {},
   "source": [
    "Our hypothesis is that users with coordinated behavior are more likely to share the same videos. If we connect users based on the videos that they post and this connection is weighted by the number of videos they have in common, we expect to see a strong community structure in coordinated users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b6a8d548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodeUserID1</th>\n",
       "      <th>platform1</th>\n",
       "      <th>nodeUserID2</th>\n",
       "      <th>platform2</th>\n",
       "      <th>sharedVideos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---0qUylIJzj8kr2P8ugDg</td>\n",
       "      <td>twitter</td>\n",
       "      <td>10118082</td>\n",
       "      <td>facebook</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>---0qUylIJzj8kr2P8ugDg</td>\n",
       "      <td>twitter</td>\n",
       "      <td>EvttAa1o56OZCUngk0flcA</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---0qUylIJzj8kr2P8ugDg</td>\n",
       "      <td>twitter</td>\n",
       "      <td>NUkHCk9oOonq8cuJKbwzFQ</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>---0qUylIJzj8kr2P8ugDg</td>\n",
       "      <td>twitter</td>\n",
       "      <td>ev2obIiRHGJBIyqvPw_SHg</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>---0qUylIJzj8kr2P8ugDg</td>\n",
       "      <td>twitter</td>\n",
       "      <td>fFH3InGzF_Xg2rUtFLg4Ag</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              nodeUserID1 platform1             nodeUserID2 platform2  \\\n",
       "0  ---0qUylIJzj8kr2P8ugDg   twitter                10118082  facebook   \n",
       "1  ---0qUylIJzj8kr2P8ugDg   twitter  EvttAa1o56OZCUngk0flcA   twitter   \n",
       "2  ---0qUylIJzj8kr2P8ugDg   twitter  NUkHCk9oOonq8cuJKbwzFQ   twitter   \n",
       "3  ---0qUylIJzj8kr2P8ugDg   twitter  ev2obIiRHGJBIyqvPw_SHg   twitter   \n",
       "4  ---0qUylIJzj8kr2P8ugDg   twitter  fFH3InGzF_Xg2rUtFLg4Ag   twitter   \n",
       "\n",
       "   sharedVideos  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfUserCounts = get_shared_video_counts(dfCombined)\n",
    "dfUserCounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7ac0c3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodes</th>\n",
       "      <th>edges</th>\n",
       "      <th>density</th>\n",
       "      <th>avg clustering</th>\n",
       "      <th>connected components</th>\n",
       "      <th>largest component size</th>\n",
       "      <th>isolates</th>\n",
       "      <th>communities</th>\n",
       "      <th>modularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>402</td>\n",
       "      <td>1597</td>\n",
       "      <td>0.01981</td>\n",
       "      <td>0.5407</td>\n",
       "      <td>10</td>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.40156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nodes  edges  density  avg clustering  connected components  \\\n",
       "0    402   1597  0.01981          0.5407                    10   \n",
       "\n",
       "   largest component size  isolates  communities  modularity  \n",
       "0                     382         0           16     0.40156  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the network of users\n",
    "G_users_network = get_users_network(dfUserCounts, min_shared_videos=3)\n",
    "\n",
    "# Writing the network to plot it in Gephi\n",
    "nx.write_gexf(G_users_network, \"users_network.gexf\")\n",
    "\n",
    "# Showing metrics from our network\n",
    "dfMetrics_users = get_network_metrics(G_users_network)\n",
    "dfMetrics_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c2c82d",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h3> Connected network of users with at least 3 shared videos </h3>\n",
    "<img src=\"images/users_network.png\" alt=\"Gephi Network\" width=\"600\" height=\"600\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3162dd46",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f69d5013",
   "metadata": {},
   "source": [
    "## Baseline Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f45bd4",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9edbf28",
   "metadata": {},
   "source": [
    "### Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66246c15",
   "metadata": {},
   "source": [
    "For the method 1, we want to remove the current relation between users and the videos that they post, but we are not going to change the frequency of the videos that were posted. We can do this by shuffling the videoID column from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a3ac19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodeUserID</th>\n",
       "      <th>nodeTime</th>\n",
       "      <th>videoID</th>\n",
       "      <th>platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>548542</td>\n",
       "      <td>2018-04-01 10:22:08</td>\n",
       "      <td>X27B0yuazGo</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5465518</td>\n",
       "      <td>2018-04-05 00:04:00</td>\n",
       "      <td>ooi1KktDVcU</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6119363</td>\n",
       "      <td>2018-04-05 07:12:02</td>\n",
       "      <td>CYflh9ltqDY</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8621215</td>\n",
       "      <td>2018-04-05 18:22:26</td>\n",
       "      <td>DPgOnD0n9uw</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12041680</td>\n",
       "      <td>2018-04-08 15:08:50</td>\n",
       "      <td>3vNwe7yKbwo</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nodeUserID            nodeTime      videoID  platform\n",
       "0     548542 2018-04-01 10:22:08  X27B0yuazGo  facebook\n",
       "1    5465518 2018-04-05 00:04:00  ooi1KktDVcU  facebook\n",
       "2    6119363 2018-04-05 07:12:02  CYflh9ltqDY  facebook\n",
       "3    8621215 2018-04-05 18:22:26  DPgOnD0n9uw  facebook\n",
       "4   12041680 2018-04-08 15:08:50  3vNwe7yKbwo  facebook"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffling the video column\n",
    "col_to_shuffle = 'videoID'\n",
    "dfCombinedM1 = dfCombined.copy()\n",
    "dfCombinedM1[col_to_shuffle] = np.random.permutation(dfCombinedM1[col_to_shuffle].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b741d5d",
   "metadata": {},
   "source": [
    "Now we can create the network with this transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db9b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>nodes</th>\n",
       "      <th>edges</th>\n",
       "      <th>density</th>\n",
       "      <th>avg clustering</th>\n",
       "      <th>connected components</th>\n",
       "      <th>largest component size</th>\n",
       "      <th>isolates</th>\n",
       "      <th>communities</th>\n",
       "      <th>modularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>6564</td>\n",
       "      <td>10262</td>\n",
       "      <td>0.00048</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>100</td>\n",
       "      <td>6235</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0.708567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Method1</td>\n",
       "      <td>6564</td>\n",
       "      <td>12568</td>\n",
       "      <td>0.00058</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>42</td>\n",
       "      <td>6472</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0.519652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  nodes  edges  density  avg clustering  connected components  \\\n",
       "0  Baseline   6564  10262  0.00048          0.0783                   100   \n",
       "1   Method1   6564  12568  0.00058          0.0085                    42   \n",
       "\n",
       "   largest component size  isolates  communities  modularity  \n",
       "0                    6235         0          136    0.708567  \n",
       "1                    6472         0           78    0.519652  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the connections between users who posted same video\n",
    "dfUserConnectionsM1 = get_user_interactions(dfCombinedM1, start_seconds_threshold = 0, end_seconds_threshold = 52)\n",
    "\n",
    "# Building the network with connections between users and videos\n",
    "G_originalM1 = build_network(dfCombinedM1)\n",
    "\n",
    "# Adding connections between users\n",
    "G_originalM1 = add_user_interaction_edges(G_originalM1, dfUserConnectionsM1)\n",
    "\n",
    "# Getting metrics from our network\n",
    "dfMetricsM1 = get_network_metrics(G_originalM1)\n",
    "\n",
    "# Concatening with the baseline metrics\n",
    "dfMetricsM1 = pd.concat([dfMetrics, dfMetricsM1], ignore_index=True)\n",
    "dfMetricsM1['Model'] = ['Baseline', 'Method1']\n",
    "cols = ['Model'] + [col for col in dfMetricsM1.columns if col != 'Model']\n",
    "dfMetricsM1 = dfMetricsM1[cols]\n",
    "dfMetricsM1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a125e2c",
   "metadata": {},
   "source": [
    "By comparing this basic metrics we can quickly notice that average clustering, communities and modularity were reduced. This is a clear sign that by shuffling the user and video relation we are destroying some of the communities as well. In an organic network, these communities should not exist or at least the change should be minimal.\n",
    "\n",
    "Now, we are going to focus again in the largest component of the network. Then we are going to plot so we can get some quick insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "32ab00fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 6472\n",
      "Number of edges: 12517\n",
      "Density: 0.0005977510387219656\n",
      "Average degree: 3.8680469715698393\n"
     ]
    }
   ],
   "source": [
    "# Getting just the largest component\n",
    "G_transformedM1 = G_originalM1.subgraph(max(nx.connected_components(G_originalM1), key=len))\n",
    "\n",
    "# Writing the network to plot it in Gephi\n",
    "nx.write_gexf(G_transformedM1, \"transformed_networkM1.gexf\")\n",
    "\n",
    "# Showing some metrics\n",
    "print(\"Number of nodes:\", G_transformedM1.number_of_nodes())\n",
    "print(\"Number of edges:\", G_transformedM1.number_of_edges())\n",
    "print(\"Density:\", nx.density(G_transformedM1))\n",
    "print(\"Average degree:\", np.mean(list(dict(G_transformedM1.degree()).values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc24f168",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h3> Connected Network of Users and Videos with Method 1 </h3>\n",
    "<img src=\"images/m1_network.png\" alt=\"Connected Network of Users and Videos with Gephi\" width=\"600\" height=\"600\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2573b66",
   "metadata": {},
   "source": [
    "We can see from the previous plot that hubs are less evident compared to the baseline network. Also there are a group of twitter users that are connected to many videos, this is the reason now this network has many twitter nodes in the center.\n",
    "\n",
    "It is evident that the network structure has changed. Specially the video nodes seem to have an uniformed distribution of degrees.\n",
    "\n",
    "Using Gephi, we noticed that connections between users were reduced. Thas is sensible since users that had a connection because they shared the same video now they are not connected because of the shuffling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08279859",
   "metadata": {},
   "source": [
    "### Method 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ace25",
   "metadata": {},
   "source": [
    "### Method 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdf050a",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adbc396",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
